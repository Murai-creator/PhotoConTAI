from telegram.ext import ApplicationBuilder, MessageHandler, filters, CallbackQueryHandler, CommandHandler, CallbackContext, Updater
from telegram import InlineKeyboardMarkup, InlineKeyboardButton
from gpt import *
import queue
#from telegram.ext.updater import Queue
from util import *
import sqlite3
from aiogram import Bot, Dispatcher, types
import tensorflow as tf
import os
import re
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import easyocr
from keras.models import load_model
from keras.preprocessing import image
from keras.applications.vgg16 import VGG16, preprocess_input
import numpy as np
import openai
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import httpx as httpx
# –°–æ–∑–¥–∞–µ–º –∏–ª–∏ –ø–æ–¥–∫–ª—é—á–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
conn = sqlite3.connect('users.db')
c = conn.cursor()
c.execute('CREATE TABLE IF NOT EXISTS users (user_id INTEGER PRIMARY KEY)')
# model = Sequential()
# model = VGG16(weights='C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5', include_top=False)
# model.load_weights('C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5')  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—É—Ç—å –∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
import tkinter as tk
from tkinter import filedialog

async def start(update, context):
    user_id = update.effective_user.id
    c.execute('INSERT OR IGNORE INTO users (user_id) VALUES (?)', (user_id,))
    conn.commit()

    dialog.mode = 'main'
    text = load_message('main')
    await send_text(update, context, text)
    await show_main_menu(update, context, {
        'start': "–ó–∞–ø—É—Å—Ç–∏—Ç—å",
        "question": "–°–ø—Ä–æ—Å–∏—Ç—å",
        'don': "–ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å",
        'count_users': "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
    })
    keyboard = [
        # [InlineKeyboardButton("–ó–∞–ø—É—Å—Ç–∏—Ç—å", callback_data='start')],
        [InlineKeyboardButton("–°–ø—Ä–æ—Å–∏—Ç—å", callback_data='question')],
        [InlineKeyboardButton("–ü–æ–¥–¥–µ—Ä–∂–∞—Ç—å", callback_data='don')],
        [InlineKeyboardButton("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π", callback_data='count_users')],
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)
    await update.message.reply_text("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=reply_markup)
BOT_TOKEN = "#"
update_queue = queue.Queue()
updater = Updater(BOT_TOKEN, update_queue)
# dispatcher = updater.dispatcher

async def question(update, context):
    # dialog.mode = 'gpt'
    await send_text(update, context, "–û—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ —Ñ–æ—Ç–æ —Å –ø–æ–¥–ø–∏—Å—å—é")
    photo = update.message.photo
    if photo:
        id_photo = photo[-1].file_id
        name_photo = update.message.caption
        await send_text(update, context, "1")

        update.message.reply_text(f"–ü–æ–ª—É—á–µ–Ω–æ —Ñ–æ—Ç–æ —Å id: {id_photo}")
        file = context.bot.get_file(photo[-1].file_id)
        file.download('photo.jpg')

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é VGG16
        model = VGG16(weights='imagenet', include_top=False)
        model.load_weights('C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5')
        img = image.load_img('photo.jpg', target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        features = model.predict(x)

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        # ... (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∏–ª–∏ –¥—Ä—É–≥–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º GPT –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
        openai.api_key = '#'
        prompt = f"–û–ø–∏—à–∏, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: '{features}'."
        gpt_response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=prompt,
            max_tokens=100,
            n=1,
            stop=None,
            temperature=0.7,
        )
        gpt_text = gpt_response.choices[0].text.strip()

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
        update.message.reply_text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏!\n\n{gpt_text}")

   #  photo = update.message.photo
   #  id_photo = photo.file_id
   #  name_photo = update.message.caption
   #
   #  # –î–µ–ª–∞–µ–º —á—Ç–æ-–Ω–∏–±—É–¥—å —Å id_photo –∏ name_photo
   #  update.message.reply_text(f"–ü–æ–ª—É—á–µ–Ω–æ —Ñ–æ—Ç–æ —Å id: {id_photo}")
   #  file = context.bot.get_file(photo.file_id)
   #  file.download('photo.jpg')
   #
   #  # –ú–æ–¥–µ–ª—å
   # # model = VGG16(weights='C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5', include_top=False)
   #  model = VGG16(weights='imagenet', include_top=False)
   #  model.load_weights('C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5')
   #  # model.load_weights('C:/Users/user/Desktop/–ü—Ä–æ–µ–∫—Ç PhotoConAI/–®–∞–±–ª–æ–Ω/model.weights.h5')  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—É—Ç—å –∫ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏
   #
   #  # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø—Ä–µ–¥–ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
   #  img = image.load_img('photo.jpg', target_size=(224, 224))
   #  x = image.img_to_array(img)
   #  x = np.expand_dims(x, axis=0)
   #  x = preprocess_input(x)
   #
   #  # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏
   #  features = model.predict(x)
   #  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (features)
   #  # –ù–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –∏—Ö –Ω–∞ —ç–∫—Ä–∞–Ω –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
   #  print(features)
   #
   #  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
   #  update.message.reply_text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏!")
   #  response = {
   #      features
   #  }
   #  # image_text = photo('modeling.weights.h5')
   #  #await handle_photo(update, context, image)
   #  #text = send_text('gpt')
   #  # await handle_photo(update, context, text)
   #  openai.api_key = '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'
   #  prompt = f"–°–¥–µ–ª–∞–π —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á"
   #  gpt_response = openai.Completion.create(
   #      engine="text-davinci-003",
   #      prompt=prompt,
   #      max_tokens=100,
   #      n=1,
   #      stop=None,
   #      temperature=0.7,
   #  )
   #  gpt_text = gpt_response.choices[0].text.strip()
   #
   #  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
   #  update.message.reply_text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–æ—Ç–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–∏! {response}\n\n{gpt_text}")
   #

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–æ—Ç–æ
# dispatcher.add_handler(MessageHandler(Filters.photo, handle_photo))

# await send_text(update, context, image, text)

async def don(update, context):
    await send_text(update, context, "–ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å, —Ç–æ –≤–æ—Ç –≤–∞–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–º–æ—â–∏:")

async def gpt_dialog(update, context):
    text = update.message.text
    prompt = load_prompt('gpt')
    await send_text(update, context, "–°–µ–π—á–∞—Å —Ä–∞–∑–±–µ—Ä–µ–º—Å—èüß†")
    answer = await chatgpt.send_question(prompt, text)
    await send_text(update, context, answer)
async def show_user_count(update, context):
    query = update.callback_query
    count = count_users()
    await query.answer()
    await query.edit_message_text(text=f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {count}')
def count_users():
    c.execute('SELECT COUNT(*) FROM users')
    return c.fetchone()[0]

async def hello(update, context):
    if dialog.mode == 'gpt':
        await gpt_dialog(update, context)
    else:
        text = load_message('main')
        await send_photo(update, context, "main")
        await send_text(update, context, text)

async def show_user_count(update, context):
    count = count_users()
    await send_text(update, context, f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {count}')
def count_users():
    c.execute('SELECT COUNT(*) FROM users')
    count = c.fetchone()[0]
    #print(f'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {count}')

dialog = Dialog()
dialog.mode = None
dialog.list = []

chatgpt = ChatGptService(token='#')  # –í—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–π –∫–ª—é—á

app = ApplicationBuilder().token("#").build()  # –í—Å—Ç–∞–≤—å—Ç–µ —Ç–æ–∫–µ–Ω –¢–ì
app.add_handler(CommandHandler("start", start))
app.add_handler(CommandHandler("question", question))
app.add_handler(CommandHandler("don", don))
app.add_handler(CommandHandler("count_users", show_user_count))
app.add_handler(CallbackQueryHandler(show_user_count, pattern='count_users'))
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, hello))

app.run_polling()

#count_users()  # –í—ã–≤–æ–¥–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ –±–æ—Ç–∞
